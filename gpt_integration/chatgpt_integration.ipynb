{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-PVNsF***************************************Durc. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ronald\\TUM Materialien\\Semester 8\\seba nlp\\ki-suscheck\\gpt_integration\\chatgpt_integration.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mannouncement\u001b[39m(language: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbytes\u001b[39m, version: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe currently used language is: \u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m and the version is: \u001b[39m\u001b[39m{\u001b[39;00mversion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m embedding \u001b[39m=\u001b[39m createEmbedding(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthe length of the embedding is: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(embedding)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m user_message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat is the project about? Give a short summary. Limit it to 20 words or less.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\Ronald\\TUM Materialien\\Semester 8\\seba nlp\\ki-suscheck\\gpt_integration\\chatgpt_integration.ipynb Cell 1\u001b[0m in \u001b[0;36mcreateEmbedding\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreateEmbedding\u001b[39m(text):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39minput\u001b[39;49m \u001b[39m=\u001b[39;49m text,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         model\u001b[39m=\u001b[39;49mEMBEDDING_MODEL\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ronald/TUM%20Materialien/Semester%208/seba%20nlp/ki-suscheck/gpt_integration/chatgpt_integration.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mprint\u001b[39m(embeddings)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-PVNsF***************************************Durc. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "# set env var\n",
    "api_key = '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'\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def createEmbedding(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input = text,\n",
    "        model=EMBEDDING_MODEL\n",
    "    )\n",
    "    \n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    print(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# TODO: save the embedding in the vector db\n",
    "\n",
    "text = \"\"\"\n",
    "1.\tIntroduction\n",
    "Aim of the research project “Sustainable shopping assistant for a healthier and more sustainable Food consumption\" is to provide consumers with a digital decision-making aid for a sustainable gene shopping for groceries. This will develop a prototype for a digital service ckelt, which, in addition to consumer health protection, serves to inform consumers. In addition, the greatest possible transparency can be created in the food chain, the handling of food resources and their appreciation as well as improving purchasing behavior and conflicting goals and systems nergies between Health, sustainability and the complex Environment transparent make, or. con flicted represent. With to the \"Sustainable shopping assistants” should a digital product develop, the AI Connects tools with blockchain-based data and natural language access to the information to via chatbot allows.\n",
    "For the Development this offer at the consumers should one basis for the Evaluation the products under consideration are created with regard to their environmental and health effects. For this a basic concept is required, which is used as the basis for the evaluation of the food become can.\n",
    "3 steps for a theoretical basic concept\n",
    "•\tbasis – determination on a sustainability approach\n",
    "•\tSelection from tools to the Depiction the sustainability aspects in the different dimension to\n",
    "•\tcreation one own Scoring Model/Weighting the dimensions\n",
    "Included should the basic concept also a clear one have goal description , How the \"sustainable shopping assistant tent\" users a sound To know provide can and this included support, itself consciously for one healthier and more sustainable food choices to decide.\n",
    "\"\"\"\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    # Return the number of tokens in a string.\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def announcement(language: str | bytes, version: float) -> str:\n",
    "    return f'The currently used language is: {language} and the version is: {version}'\n",
    "\n",
    "embedding = createEmbedding(text)\n",
    "\n",
    "print(f'the length of the embedding is: {len(embedding)}')\n",
    "\n",
    "user_message = \"What is the project about? Give a short summary. Limit it to 20 words or less.\\n:\"\n",
    "\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You answer based on the following text that is used as your knowledge base.\"},\n",
    "            {\"role\": \"user\", \"content\": user_message + text}]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = GPT_MODEL, \n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "response_message = response[\"choices\"][0][\"message\"]\n",
    "print(response_message)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seba-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
